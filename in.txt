package org.apache.spark.bagel  import org.apache.spark._ import org.apache.spark.SparkContext._ import org.apache.spark.rdd.RDD import org.apache.spark.storage.StorageLevel  object Bagel extends Logging {   val DEFAULT_STORAGE_LEVEL = StorageLevel.MEMORY_AND_DISK    /**    * Runs a Bagel program.    * @param sc org.apache.spark.SparkContext to use for the program.    * @param vertices vertices of the graph represented as an RDD of (Key, Vertex) pairs. Often the    *                 Key will be the vertex id.    * @param messages initial set of messages represented as an RDD of (Key, Message) pairs. Often    *                 this will be an empty array, i.e. sc.parallelize(Array[K, Message]()).    * @param combiner [[org.apache.spark.bagel.Combiner]] combines multiple individual messages to a    *                 given vertex into one message before sending (which often involves network    *                 I/O).    * @param aggregator [[org.apache.spark.bagel.Aggregator]] performs a reduce across all vertices    *                  after each superstep and provides the result to each vertex in the next    *                  superstep.    * @param partitioner org.apache.spark.Partitioner partitions values by key    * @param numPartitions number of partitions across which to split the graph.    *                      Default is the default parallelism of the SparkContext    * @param storageLevel org.apache.spark.storage.StorageLevel to use for caching of    *                    intermediate RDDs in each superstep. Defaults to caching in memory.    * @param compute function that takes a Vertex, optional set of (possibly combined) messages to    *                the Vertex, optional Aggregator and the current superstep,    *                and returns a set of (Vertex, outgoing Messages) pairs    * @tparam K key    * @tparam V vertex type    * @tparam M message type    * @tparam C combiner    * @tparam A aggregator    * @return an RDD of (K, V) pairs representing the graph after completion of the program    */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest,           C: Manifest, A: Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     combiner: Combiner[M, C],     aggregator: Option[Aggregator[V, A]],     partitioner: Partitioner,     numPartitions: Int,     storageLevel: StorageLevel = DEFAULT_STORAGE_LEVEL   )(     compute: (V, Option[C], Option[A], Int) => (V, Array[M])   ): RDD[(K, V)] = {     val splits = if (numPartitions != 0) numPartitions else sc.defaultParallelism      var superstep = 0     var verts = vertices     var msgs = messages     var noActivity = false     var lastRDD: RDD[(K, (V, Array[M]))] = null     do {       logInfo("Starting superstep " + superstep + ".")       val startTime = System.currentTimeMillis        val aggregated = agg(verts, aggregator)       val combinedMsgs = msgs.combineByKey(         combiner.createCombiner _, combiner.mergeMsg _, combiner.mergeCombiners _, partitioner)       val grouped = combinedMsgs.groupWith(verts)       val superstep_ = superstep  // Create a read-only copy of superstep for capture in closure       val (processed, numMsgs, numActiveVerts) =         comp[K, V, M, C](sc, grouped, compute(_, _, aggregated, superstep_), storageLevel)       if (lastRDD != null) {         lastRDD.unpersist(false)       }       lastRDD = processed        val timeTaken = System.currentTimeMillis - startTime       logInfo("Superstep %d took %d s".format(superstep, timeTaken / 1000))        verts = processed.mapValues { case (vert, msgs) => vert }       msgs = processed.flatMap {         case (id, (vert, msgs)) => msgs.map(m => (m.targetId, m))       }       superstep += 1        noActivity = numMsgs == 0 && numActiveVerts == 0     } while (!noActivity)      verts   }    /** Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]] and the default     * storage level */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest, C: Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     combiner: Combiner[M, C],     partitioner: Partitioner,     numPartitions: Int   )(     compute: (V, Option[C], Int) => (V, Array[M])): RDD[(K, V)] = run(sc, vertices, messages,         combiner, numPartitions, DEFAULT_STORAGE_LEVEL)(compute)    /** Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]] */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest, C: Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     combiner: Combiner[M, C],     partitioner: Partitioner,     numPartitions: Int,     storageLevel: StorageLevel   )(     compute: (V, Option[C], Int) => (V, Array[M])   ): RDD[(K, V)] = {     run[K, V, M, C, Nothing](       sc, vertices, messages, combiner, None, partitioner, numPartitions, storageLevel)(       addAggregatorArg[K, V, M, C](compute))   }    /**    * Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]], default    * org.apache.spark.HashPartitioner and default storage level    */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest, C: Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     combiner: Combiner[M, C],     numPartitions: Int   )(     compute: (V, Option[C], Int) => (V, Array[M])   ): RDD[(K, V)] = run(sc, vertices, messages, combiner, numPartitions,       DEFAULT_STORAGE_LEVEL)(compute)    /**    * Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]] and the    * default org.apache.spark.HashPartitioner    */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest, C: Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     combiner: Combiner[M, C],     numPartitions: Int,     storageLevel: StorageLevel   )(     compute: (V, Option[C], Int) => (V, Array[M])   ): RDD[(K, V)] = {     val part = new HashPartitioner(numPartitions)     run[K, V, M, C, Nothing](       sc, vertices, messages, combiner, None, part, numPartitions, storageLevel)(       addAggregatorArg[K, V, M, C](compute))   }    /**    * Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]],    * default org.apache.spark.HashPartitioner,    * [[org.apache.spark.bagel.DefaultCombiner]] and the default storage level    */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     numPartitions: Int   )(     compute: (V, Option[Array[M]], Int) => (V, Array[M])   ): RDD[(K, V)] = run(sc, vertices, messages, numPartitions, DEFAULT_STORAGE_LEVEL)(compute)    /**    * Runs a Bagel program with no [[org.apache.spark.bagel.Aggregator]],    * the default org.apache.spark.HashPartitioner    * and [[org.apache.spark.bagel.DefaultCombiner]]    */   def run[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest](     sc: SparkContext,     vertices: RDD[(K, V)],     messages: RDD[(K, M)],     numPartitions: Int,     storageLevel: StorageLevel    )(     compute: (V, Option[Array[M]], Int) => (V, Array[M])    ): RDD[(K, V)] = {     val part = new HashPartitioner(numPartitions)     run[K, V, M, Array[M], Nothing](       sc, vertices, messages, new DefaultCombiner(), None, part, numPartitions, storageLevel)(       addAggregatorArg[K, V, M, Array[M]](compute))   }    /**    * Aggregates the given vertices using the given aggregator, if it    * is specified.    */   private def agg[K, V <: Vertex, A: Manifest](     verts: RDD[(K, V)],     aggregator: Option[Aggregator[V, A]]   ): Option[A] = aggregator match {     case Some(a) =>       Some(verts.map {         case (id, vert) => a.createAggregator(vert)       }.reduce(a.mergeAggregators(_, _)))     case None => None   }    /**    * Processes the given vertex-message RDD using the compute    * function. Returns the processed RDD, the number of messages    * created, and the number of active vertices.    */   private def comp[K: Manifest, V <: Vertex, M <: Message[K], C](     sc: SparkContext,     grouped: RDD[(K, (Iterable[C], Iterable[V]))],     compute: (V, Option[C]) => (V, Array[M]),     storageLevel: StorageLevel   ): (RDD[(K, (V, Array[M]))], Int, Int) = {     var numMsgs = sc.accumulator(0)     var numActiveVerts = sc.accumulator(0)     val processed = grouped.mapValues(x => (x._1.iterator, x._2.iterator))       .flatMapValues {       case (_, vs) if !vs.hasNext => None       case (c, vs) => {         val (newVert, newMsgs) =           compute(vs.next,             c.hasNext match {               case true => Some(c.next)               case false => None             }           )          numMsgs += newMsgs.size         if (newVert.active) {           numActiveVerts += 1         }          Some((newVert, newMsgs))       }     }.persist(storageLevel)      // Force evaluation of processed RDD for accurate performance measurements     processed.foreach(x => {})      (processed, numMsgs.value, numActiveVerts.value)   }    /**    * Converts a compute function that doesn't take an aggregator to    * one that does, so it can be passed to Bagel.run.    */   private def addAggregatorArg[K: Manifest, V <: Vertex : Manifest, M <: Message[K] : Manifest, C](     compute: (V, Option[C], Int) => (V, Array[M])   ): (V, Option[C], Option[Nothing], Int) => (V, Array[M]) = {     (vert: V, msgs: Option[C], aggregated: Option[Nothing], superstep: Int) =>       compute(vert, msgs, superstep)   } }  trait Combiner[M, C] {   def createCombiner(msg: M): C   def mergeMsg(combiner: C, msg: M): C   def mergeCombiners(a: C, b: C): C }  trait Aggregator[V, A] {   def createAggregator(vert: V): A   def mergeAggregators(a: A, b: A): A }  /** Default combiner that simply appends messages together (i.e. performs no aggregation) */ class DefaultCombiner[M: Manifest] extends Combiner[M, Array[M]] with Serializable {   def createCombiner(msg: M): Array[M] =     Array(msg)   def mergeMsg(combiner: Array[M], msg: M): Array[M] =     combiner :+ msg   def mergeCombiners(a: Array[M], b: Array[M]): Array[M] =     a ++ b }  /**  * Represents a Bagel vertex.  *  * Subclasses may store state along with each vertex and must  * inherit from java.io.Serializable or scala.Serializable.  */ trait Vertex {   def active: Boolean }  /**  * Represents a Bagel message to a target vertex.  *  * Subclasses may contain a payload to deliver to the target vertex  * and must inherit from java.io.Serializable or scala.Serializable.  */ trait Message[K] {   def targetId: K } 
Bagel: An implementation of Pregel in Spark. THIS IS DEPRECATED - use Spark's GraphX library.  */ package org.apache.spark.bagel; 
package org.apache.spark  /**  * Bagel: An implementation of Pregel in Spark. THIS IS DEPRECATED - use Spark's GraphX library.  */ package object bagel 
package org.apache.spark.bagel  import org.scalatest.{BeforeAndAfter, Assertions} import org.scalatest.concurrent.Timeouts import org.scalatest.time.SpanSugar._  import org.apache.spark._ import org.apache.spark.storage.StorageLevel  class TestVertex(val active: Boolean, val age: Int) extends Vertex with Serializable class TestMessage(val targetId: String) extends Message[String] with Serializable  class BagelSuite extends SparkFunSuite with Assertions with BeforeAndAfter with Timeouts {    var sc: SparkContext = _    after {     if (sc != null) {       sc.stop()       sc = null     }   }    test("halting by voting") {     sc = new SparkContext("local", "test")     val verts = sc.parallelize(Array("a", "b", "c", "d").map(id => (id, new TestVertex(true, 0))))     val msgs = sc.parallelize(Array[(String, TestMessage)]())     val numSupersteps = 5     val result =       Bagel.run(sc, verts, msgs, sc.defaultParallelism) {         (self: TestVertex, msgs: Option[Array[TestMessage]], superstep: Int) =>           (new TestVertex(superstep < numSupersteps - 1, self.age + 1), Array[TestMessage]())       }     for ((id, vert) <- result.collect) {       assert(vert.age === numSupersteps)     }   }    test("halting by message silence") {     sc = new SparkContext("local", "test")     val verts = sc.parallelize(Array("a", "b", "c", "d").map(id => (id, new TestVertex(false, 0))))     val msgs = sc.parallelize(Array("a" -> new TestMessage("a")))     val numSupersteps = 5     val result =       Bagel.run(sc, verts, msgs, sc.defaultParallelism) {         (self: TestVertex, msgs: Option[Array[TestMessage]], superstep: Int) =>           val msgsOut =             msgs match {               case Some(ms) if (superstep < numSupersteps - 1) =>                 ms               case _ =>                 Array[TestMessage]()             }         (new TestVertex(self.active, self.age + 1), msgsOut)       }     for ((id, vert) <- result.collect) {       assert(vert.age === numSupersteps)     }   }    test("large number of iterations") {     // This tests whether jobs with a large number of iterations finish in a reasonable time,     // because non-memoized recursion in RDD or DAGScheduler used to cause them to hang     failAfter(30 seconds) {       sc = new SparkContext("local", "test")       val verts = sc.parallelize((1 to 4).map(id => (id.toString, new TestVertex(true, 0))))       val msgs = sc.parallelize(Array[(String, TestMessage)]())       val numSupersteps = 50       val result =         Bagel.run(sc, verts, msgs, sc.defaultParallelism) {           (self: TestVertex, msgs: Option[Array[TestMessage]], superstep: Int) =>             (new TestVertex(superstep < numSupersteps - 1, self.age + 1), Array[TestMessage]())         }       for ((id, vert) <- result.collect) {         assert(vert.age === numSupersteps)       }     }   }    test("using non-default persistence level") {     failAfter(10 seconds) {       sc = new SparkContext("local", "test")       val verts = sc.parallelize((1 to 4).map(id => (id.toString, new TestVertex(true, 0))))       val msgs = sc.parallelize(Array[(String, TestMessage)]())       val numSupersteps = 20       val result =         Bagel.run(sc, verts, msgs, sc.defaultParallelism, StorageLevel.DISK_ONLY) {           (self: TestVertex, msgs: Option[Array[TestMessage]], superstep: Int) =>             (new TestVertex(superstep < numSupersteps - 1, self.age + 1), Array[TestMessage]())         }       for ((id, vert) <- result.collect) {         assert(vert.age === numSupersteps)       }     }   } } 
#!/usr/bin/env bash  # #  #  # This script loads spark-env.sh if it exists, and ensures it is only loaded once. # spark-env.sh is loaded from SPARK_CONF_DIR if set, or within the current directory's # conf/ subdirectory. FWDIR="$(cd "`dirname "$0"`"/..; pwd)"  if [ -z "$SPARK_ENV_LOADED" ]; then   export SPARK_ENV_LOADED=1    # Returns the parent of the directory this script lives in.   parent_dir="$(cd "`dirname "$0"`"/..; pwd)"    user_conf_dir="${SPARK_CONF_DIR:-"$parent_dir"/conf}"    if [ -f "${user_conf_dir}/spark-env.sh" ]; then     # Promote all variable declarations to environment (exported) variables     set -a     . "${user_conf_dir}/spark-env.sh"     set +a   fi fi  # Setting SPARK_SCALA_VERSION if not already set.  if [ -z "$SPARK_SCALA_VERSION" ]; then      ASSEMBLY_DIR2="$FWDIR/assembly/target/scala-2.11"     ASSEMBLY_DIR1="$FWDIR/assembly/target/scala-2.10"      if [[ -d "$ASSEMBLY_DIR2" && -d "$ASSEMBLY_DIR1" ]]; then         echo -e "Presence of build for both scala versions(SCALA 2.10 and SCALA 2.11) detected." 1>&2         echo -e 'Either clean one of them or, export SPARK_SCALA_VERSION=2.11 in spark-env.sh.' 1>&2         exit 1     fi      if [ -d "$ASSEMBLY_DIR2" ]; then         export SPARK_SCALA_VERSION="2.11"     else         export SPARK_SCALA_VERSION="2.10"     fi fi 
## Contributing to Spark  *Before opening a pull request*, review the  [Contributing to Spark wiki](https://cwiki.apache.org/confluence/display/SPARK/Contributing+to+Spark).  It lists steps that are required before creating a PR. In particular, consider:  - Is the change important and ready enough to ask the community to spend time reviewing? - Have you searched for existing, related JIRAs and pull requests? - Is this a new feature that can stand alone as a package on http://spark-packages.org ? - Is the change being proposed clearly explained and motivated?  When you contribute code, you affirm that the contribution is your original work and that you  license the work to the project under the project's open source license. Whether or not you  state this explicitly, by submitting any copyrighted material via pull request, email, or  other means you agree to license the material under the project's open source license and  warrant that you have the legal authority to do so. 
package org.apache.spark.api.java.function;  import java.io.Serializable;  /**  * A function that returns zero or more records of type Double from each input record.  */ public interface DoubleFlatMapFunction<T> extends Serializable {   public Iterable<Double> call(T t) throws Exception; } 
package org.apache.spark.api.java.function;  import java.io.Serializable;  /**  *  A function that returns Doubles, and can be used to construct DoubleRDDs.  */ public interface DoubleFunction<T> extends Serializable {   public double call(T t) throws Exception; } 
package org.apache.spark.api.java.function;  import java.io.Serializable;  /**  * A function that returns zero or more output records from each input record.  */ public interface FlatMapFunction<T, R> extends Serializable {   public Iterable<R> call(T t) throws Exception; } 
package org.apache.spark.api.java.function;  import java.io.Serializable;  /**  * A function that takes two inputs and returns zero or more output records.  */ public interface FlatMapFunction2<T1, T2, R> extends Serializable {   public Iterable<R> call(T1 t1, T2 t2) throws Exception; } 
